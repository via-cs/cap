dataset:
  path: "../cap/dataset/ElectricityTransformer/et_data.txt"
  batch_size: 32
  train_size: 0.8
  valid_size: 0.1
  test_size: 0.1

model:
  type: "catp"
  hidden_dim: 128
  num_layers: 2
  dropout: 0.1

  # Manager configuration
  manager:
    d_model: 256
    n_heads: 4
    d_ff: 1024
    num_layers: 2
    dropout: 0.2

  # Worker configurations
  workers:
    lstm_workers:
      - name: "lstm_large"
        hidden_dim: 256
        num_layers: 2
        dropout: 0.1
      - name: "lstm_medium"
        hidden_dim: 128
        num_layers: 1
        dropout: 0.1
      - name: "lstm_deep"
        hidden_dim: 512
        num_layers: 3
        dropout: 0.2
      - name: "lstm_small"
        hidden_dim: 64
        num_layers: 2
        dropout: 0.15
    
    transformer_workers:
      - name: "transformer_medium"
        d_model: 128
        n_heads: 4
        d_ff: 256
        num_layers: 2
        dropout: 0.1
      - name: "transformer_small"
        d_model: 64
        n_heads: 2
        d_ff: 128
        num_layers: 1
        dropout: 0.15

training:
  epochs: 50
  manager_learning_rate: 0.005
  worker_learning_rate: 0.001
  patience: 5
  device: "cuda"
  clip_value: 0.5
  worker_update_steps: 1 